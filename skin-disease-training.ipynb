{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dir=\"dermnet/train\"\n",
    "val_dir=\"dermnet/test\"\n",
    "\n",
    "#ViT - pretrenirani base model koji dijeli sliku na 16x16, ocekuje da ulazne slike imaju dimenzije 224x224 piksela i treniran je na ImageNet-21k skupu\n",
    "image_processor=ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "#Transformacija slika, 224x224, pretvara u tenzor format koji PyTorch koristi za sve podatke, te normalizuje vrijednosti piksela po kanalima (R,G,B)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std) \n",
    "    #Nakon sto se slika pretvori u tenzor oduzmi srednju vrijednost (mean) i podijeli sa standardnom devijacijom, \n",
    "    #da bi slike bile u istom rasponu kao slike na kojima je ViT treniran\n",
    "    #sto pomaze tacnosti\n",
    "    #Npr. ako je image_processor.image_mean = [0.5, 0.5, 0.5]\n",
    "    #image_processor.image_std = [0.5, 0.5, 0.5], onda:\n",
    "    #piksel vrijednosti 0.6 na R kanalu postaje:\n",
    "    #(0.6 - 0.5) / 0.5 = 0.2\n",
    "])\n",
    "\n",
    "#Ucitavamo dataset\n",
    "train_dataset = datasets.ImageFolder(root = train_dir, transform = transform)\n",
    "val_dataset = datasets.ImageFolder(root = val_dir, transform = transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "\n",
    "#detektujemo nazive foldera\n",
    "class_names = train_dataset.classes \n",
    "#broji koliko ima razlicitih klasa\n",
    "num_classes = len(class_names)\n",
    "#Ispisujemo klase\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels = num_classes\n",
    ")\n",
    "#premjestamo model na cpu ili gpu kako bi model i svi njegovi parametri bili na istom device-u\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#AdamW - algoritam optimizacije. Cilj mu je da efikasno i stabilno pronađe najbolje tezine modela tako sto smanjuje gresku tokom treniranja\n",
    "# pomaze da model ne preuzi podatke, lr=2e-5 je learning rate(stopa ucenja) i iznosi 0.00002 - koliko brzo optimizator prilagođava parametre\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=10):\n",
    "    train_losses, val_losses, train_accs, val_accs =[], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() #prebacujemo model u trening rezim, omogucava da se specijalni slojevi poput dropout i \n",
    "        #batch normalization ponasaju kako treba tokom treninga\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        brojac = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            brojac+=1\n",
    "            print(f\"Batch počinje... {brojac}\")\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            running_loss+= loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #zbir tacno klasifikovanih primjera u ovom batchu\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #zbir primjera obrađenih u batchu\n",
    "            total += labels.size(0) \n",
    "        \n",
    "        train_loss = running_loss / len(train_loader) #prosjecan gubitak po batchu\n",
    "        train_acc = correct/total #ukupna tacnost \n",
    "\n",
    "        #prebacujemo model u evaluacijski režim\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad(): #racunanje sve unutar bloka bez pracenja gradijenata da ne bi trosili resurse na nepotrebno racunanje gradijenata\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        #Dodajemo teenutne vrijednosti gubitaka i tacnosti za trening i validaciju  u odgovarajuce lsite da bi ih kasnije mogao graficki prikazati i analizirati\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Validation loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "print(\"CUDA dostupna:\", torch.cuda.is_available())\n",
    "print(\"Trenutni uređaj:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_losses, val_losses, train_accs, val_accs = train(model, train_loader, val_loader, epochs=2)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d38192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
