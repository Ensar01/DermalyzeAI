{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA dostupna: True\n",
      "Trenutni uređaj: NVIDIA GeForce GTX 1050 Ti\n",
      "Epoha počinje... 1\n",
      "Epoch [1/10] - Loss: 2.4627, Accuracy: 0.3297, Validation loss: 2.0910, Validation Accuracy: 0.4395\n",
      "Epoha počinje... 1\n",
      "Epoch [2/10] - Loss: 1.7995, Accuracy: 0.5252, Validation loss: 1.6738, Validation Accuracy: 0.5452\n",
      "Epoha počinje... 1\n",
      "Epoch [3/10] - Loss: 1.2588, Accuracy: 0.6837, Validation loss: 1.4207, Validation Accuracy: 0.6084\n",
      "Epoha počinje... 1\n",
      "Epoch [4/10] - Loss: 0.7928, Accuracy: 0.8086, Validation loss: 1.3129, Validation Accuracy: 0.6319\n",
      "Epoha počinje... 1\n",
      "Epoch [5/10] - Loss: 0.4701, Accuracy: 0.8882, Validation loss: 1.3055, Validation Accuracy: 0.6387\n",
      "Epoha počinje... 1\n",
      "Epoch [6/10] - Loss: 0.2879, Accuracy: 0.9319, Validation loss: 1.3818, Validation Accuracy: 0.6179\n",
      "Epoha počinje... 1\n",
      "Epoch [7/10] - Loss: 0.1881, Accuracy: 0.9540, Validation loss: 1.3744, Validation Accuracy: 0.6324\n",
      "Epoha počinje... 1\n",
      "Epoch [8/10] - Loss: 0.1424, Accuracy: 0.9583, Validation loss: 1.4380, Validation Accuracy: 0.6377\n",
      "Epoha počinje... 1\n",
      "Epoch [9/10] - Loss: 0.1104, Accuracy: 0.9639, Validation loss: 1.5093, Validation Accuracy: 0.6352\n",
      "Epoha počinje... 1\n",
      "Epoch [10/10] - Loss: 0.1213, Accuracy: 0.9567, Validation loss: 1.4968, Validation Accuracy: 0.6394\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dir=\"dermnet/train\"\n",
    "val_dir=\"dermnet/test\"\n",
    "\n",
    "#ViT - pretrenirani base model koji dijeli sliku na 16x16, ocekuje da ulazne slike imaju dimenzije 224x224 piksela i treniran je na ImageNet-21k skupu\n",
    "image_processor=ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "#Transformacija slika, 224x224, pretvara u tenzor format koji PyTorch koristi za sve podatke, te normalizuje vrijednosti piksela po kanalima (R,G,B)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std) \n",
    "    #Nakon sto se slika pretvori u tenzor oduzmi srednju vrijednost (mean) i podijeli sa standardnom devijacijom, \n",
    "    #da bi slike bile u istom rasponu kao slike na kojima je ViT treniran\n",
    "    #sto pomaze tacnosti\n",
    "    #Npr. ako je image_processor.image_mean = [0.5, 0.5, 0.5]\n",
    "    #image_processor.image_std = [0.5, 0.5, 0.5], onda:\n",
    "    #piksel vrijednosti 0.6 na R kanalu postaje:\n",
    "    #(0.6 - 0.5) / 0.5 = 0.2\n",
    "])\n",
    "\n",
    "#Ucitavamo dataset\n",
    "train_dataset = datasets.ImageFolder(root = train_dir, transform = transform)\n",
    "val_dataset = datasets.ImageFolder(root = val_dir, transform = transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "\n",
    "#detektujemo nazive foldera\n",
    "class_names = train_dataset.classes \n",
    "#broji koliko ima razlicitih klasa\n",
    "num_classes = len(class_names)\n",
    "#Ispisujemo klase\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels = num_classes\n",
    ")\n",
    "#premjestamo model na cpu ili gpu kako bi model i svi njegovi parametri bili na istom device-u\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#AdamW - algoritam optimizacije. Cilj mu je da efikasno i stabilno pronađe najbolje tezine modela tako sto smanjuje gresku tokom treniranja\n",
    "# pomaze da model ne preuzi podatke, lr=2e-5 je learning rate(stopa ucenja) i iznosi 0.00002 - koliko brzo optimizator prilagođava parametre\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=10):\n",
    "    train_losses, val_losses, train_accs, val_accs =[], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() #prebacujemo model u trening rezim, omogucava da se specijalni slojevi poput dropout i \n",
    "        #batch normalization ponasaju kako treba tokom treninga\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        brojac = 0\n",
    "        brojac+=1\n",
    "        print(f\"Epoha počinje... {brojac}\")\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            running_loss+= loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #zbir tacno klasifikovanih primjera u ovom batchu\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #zbir primjera obrađenih u batchu\n",
    "            total += labels.size(0) \n",
    "        \n",
    "        train_loss = running_loss / len(train_loader) #prosjecan gubitak po batchu\n",
    "        train_acc = correct/total #ukupna tacnost \n",
    "\n",
    "        #prebacujemo model u evaluacijski režim\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad(): #racunanje sve unutar bloka bez pracenja gradijenata da ne bi trosili resurse na nepotrebno racunanje gradijenata\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        #Dodajemo teenutne vrijednosti gubitaka i tacnosti za trening i validaciju  u odgovarajuce lsite da bi ih kasnije mogao graficki prikazati i analizirati\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Validation loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "print(\"CUDA dostupna:\", torch.cuda.is_available())\n",
    "print(\"Trenutni uređaj:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs = train(model, train_loader, val_loader, epochs=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d38192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sacuvan\n"
     ]
    }
   ],
   "source": [
    "#cuva trenirane tezine(parametre modela)\n",
    "torch.save(model.state_dict(), \"ViTmodel_weights.pth\")\n",
    "\n",
    "\n",
    "print(\"Model sacuvan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
