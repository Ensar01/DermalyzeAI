{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dir=\"dermnet/train\"\n",
    "val_dir=\"dermnet/test\"\n",
    "\n",
    "#ViT - pretrenirani base model koji dijeli sliku na 16x16, ocekuje da ulazne slike imaju dimenzije 224x224 piksela i treniran je na ImageNet-21k skupu\n",
    "image_processor=ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "#Transformacija slika, 224x224, pretvara u tenzor format koji PyTorch koristi za sve podatke, te normalizuje vrijednosti piksela po kanalima (R,G,B)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std) \n",
    "    #Nakon sto se slika pretvori u tenzor oduzmi srednju vrijednost (mean) i podijeli sa standardnom devijacijom, \n",
    "    #da bi slike bile u istom rasponu kao slike na kojima je ViT treniran\n",
    "    #sto pomaze tacnosti\n",
    "    #Npr. ako je image_processor.image_mean = [0.5, 0.5, 0.5]\n",
    "    #image_processor.image_std = [0.5, 0.5, 0.5], onda:\n",
    "    #piksel vrijednosti 0.6 na R kanalu postaje:\n",
    "    #(0.6 - 0.5) / 0.5 = 0.2\n",
    "])\n",
    "\n",
    "#Ucitavamo dataset\n",
    "train_dataset = datasets.ImageFolder(root = train_dir, transform = transform)\n",
    "val_dataset = datasets.ImageFolder(root = val_dir, transform = transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "\n",
    "#detektujemo nazive foldera\n",
    "class_names = train_dataset.classes \n",
    "#broji koliko ima razlicitih klasa\n",
    "num_classes = len(class_names)\n",
    "#Ispisujemo klase\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels = num_classes\n",
    ")\n",
    "#premjestamo model na cpu ili gpu kako bi model i svi njegovi parametri bili na istom device-u\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#AdamW - algoritam optimizacije. Cilj mu je da efikasno i stabilno pronađe najbolje tezine modela tako sto smanjuje gresku tokom treniranja\n",
    "# pomaze da model ne preuzi podatke, lr=2e-5 je learning rate(stopa ucenja) i iznosi 0.00002 - koliko brzo optimizator prilagođava parametre\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=10, patience=3):\n",
    "    train_losses, val_losses, train_accs, val_accs =[], [], [], []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train() #prebacujemo model u trening rezim, omogucava da se specijalni slojevi poput dropout i \n",
    "        #batch normalization ponasaju kako treba tokom treninga\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        \n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            running_loss+= loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            #zbir tacno klasifikovanih primjera u ovom batchu\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #zbir primjera obrađenih u batchu\n",
    "            total += labels.size(0) \n",
    "        \n",
    "        train_loss = running_loss / len(train_loader) #prosjecan gubitak po batchu\n",
    "        train_acc = correct/total #ukupna tacnost \n",
    "\n",
    "        #prebacujemo model u evaluacijski režim\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad(): #racunanje sve unutar bloka bez pracenja gradijenata da ne bi trosili resurse na nepotrebno racunanje gradijenata\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images).logits\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        #Dodajemo teenutne vrijednosti gubitaka i tacnosti za trening i validaciju  u odgovarajuce lsite da bi ih kasnije mogao graficki prikazati i analizirati\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Validation loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Čuvamo najbolje težine\n",
    "            torch.save(model.state_dict(), \"ViTbestmodel_weights.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Nema poboljšanja {patience_counter}/{patience} epoha.\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Rano zaustavljanje - validacija se ne poboljšava.\")\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "print(\"CUDA dostupna:\", torch.cuda.is_available())\n",
    "print(\"Trenutni uređaj:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs = train(model, train_loader, val_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdea5663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Acne and Rosacea Photos\n",
      "Confidence Score: 96.97\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "\n",
    "class_names = [\n",
    "    'Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', \n",
    "    'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', \n",
    "    'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', \n",
    "    'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', \n",
    "    'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', \n",
    "    'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', \n",
    "    'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', \n",
    "    'Warts Molluscum and other Viral Infections'\n",
    "]\n",
    "image_processor=ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels = len(class_names)\n",
    ")\n",
    "\n",
    "#ucitavamo tezine koje smo prethodno sacuvali tokom treninga i nakon ovog koraka model je 100% identican onom koji je bio treniran \n",
    "model.load_state_dict(torch.load(\"ViTbestmodel_weights.pth\", map_location=torch.device(\"cpu\")))\n",
    "model.eval()\n",
    "\n",
    "def process_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "    ])\n",
    "    #Nakon sto se slika pretvori u tenzor oduzmi srednju vrijednost (mean) i podijeli sa standardnom devijacijom, \n",
    "    #da bi slike bile u istom rasponu kao slike na kojima je ViT treniran\n",
    "    #sto pomaze tacnosti\n",
    "    #Npr. ako je image_processor.image_mean = [0.5, 0.5, 0.5]\n",
    "    #image_processor.image_std = [0.5, 0.5, 0.5], onda:\n",
    "    #piksel vrijednosti 0.6 na R kanalu postaje:\n",
    "    #(0.6 - 0.5) / 0.5 = 0.2\n",
    "    \n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "def classify_image(image_path):\n",
    "    image = process_image(image_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image).logits\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
    "        confidence, predicted_class = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_name = class_names[predicted_class.item()]\n",
    "    confidence_score = confidence.item() * 100 \n",
    "\n",
    "    print(f\"Predicted class: {predicted_name}\")\n",
    "    print(f\"Confidence Score: {confidence_score:.2f}\")\n",
    "\n",
    "image_path = \"acne.jpg\"\n",
    "classify_image(image_path)    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
